{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a38a6a4",
   "metadata": {},
   "source": [
    "# Prompt Engineering Fundamentals: Zero-Shot Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc343161",
   "metadata": {},
   "source": [
    "Learn how an LLM performs without prior examples or reasoning hints.\n",
    "Concept: The model must rely purely on its internal knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee825a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\IDA\\Documents\\agentic_ai\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      " ZERO-SHOT PROMPTING – GPT-4 vs Gemini 2.5 Flash\n",
      "================================================================================\n",
      "\n",
      "TASK: SUMMARY\n",
      "Prompt: Summarize the following headline in two lines: 'Global AI summit reveals new ethical standards for autonomous systems.'\n",
      "\n",
      " GPT-4 Response:\n",
      "A global AI summit has established new ethical standards for autonomous systems. These guidelines aim to ensure responsible development and deployment of AI technologies.\n",
      "\n",
      " Gemini Response:\n",
      "A global AI summit has unveiled\n",
      "new ethical standards for autonomous systems.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "TASK: TRANSLATION\n",
      "Prompt: Translate this to French: 'Machine learning is transforming healthcare diagnostics.'\n",
      "\n",
      " GPT-4 Response:\n",
      "\"L'apprentissage automatique transforme le diagnostic médical.\"\n",
      "\n",
      " Gemini Response:\n",
      "Here are a few options, depending on the nuance you want:\n",
      "\n",
      "**Most common and direct:**\n",
      "*   **L'apprentissage automatique transforme les diagnostics médicaux.**\n",
      "    *(This is very natural and widely understood.)*\n",
      "\n",
      "**Slightly more formal, emphasizing the \"healthcare domain\":**\n",
      "*   **L'apprentissage automatique transforme les diagnostics dans le domaine de la santé.**\n",
      "\n",
      "**Using a stronger verb for \"transforming\":**\n",
      "*   **L'apprentissage automatique révolutionne les diagnostics médicaux.**\n",
      "    *(If \"transforming\" implies a revolutionary change.)*\n",
      "\n",
      "All are correct, but the first one is likely the most straightforward and commonly used.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "TASK: CREATIVE\n",
      "Prompt: Write a haiku about data privacy.\n",
      "\n",
      " GPT-4 Response:\n",
      "Whispers in the cloud,  \n",
      "Guard your secrets, shadows loom—  \n",
      "Trust in code, not eyes.\n",
      "\n",
      " Gemini Response:\n",
      "Digital whispers,\n",
      "Unseen eyes watch all we share,\n",
      "Guard your private self.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Reflection: Observe fluency, tone, and factual accuracy without guidance.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Prompt Engineering Fundamentals – Zero-Shot Prompting\n",
    "Goal: Evaluate how GPT-4 and Gemini perform without any examples or reasoning hints.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Load API keys from environment\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if not OPENAI_API_KEY or not GOOGLE_API_KEY:\n",
    "    raise SystemExit(\"Please set both OPENAI_API_KEY and GOOGLE_API_KEY in your .env file.\")\n",
    "\n",
    "# Initialize clients\n",
    "openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# Zero-shot prompts\n",
    "prompts = {\n",
    "    \"summary\": \"Summarize the following headline in two lines: 'Global AI summit reveals new ethical standards for autonomous systems.'\",\n",
    "    \"translation\": \"Translate this to French: 'Machine learning is transforming healthcare diagnostics.'\",\n",
    "    \"creative\": \"Write a haiku about data privacy.\"\n",
    "}\n",
    "\n",
    "def query_openai(prompt):\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.7\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def query_gemini(prompt):\n",
    "    model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text.strip() if response.text else \"(No response returned.)\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\" ZERO-SHOT PROMPTING – GPT-4 vs Gemini 2.5 Flash\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for task, text in prompts.items():\n",
    "    print(f\"\\nTASK: {task.upper()}\")\n",
    "    print(f\"Prompt: {text}\\n\")\n",
    "\n",
    "    print(\" GPT-4 Response:\")\n",
    "    try:\n",
    "        print(query_openai(text))\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying OpenAI: {e}\")\n",
    "\n",
    "    print(\"\\n Gemini Response:\")\n",
    "    try:\n",
    "        print(query_gemini(text))\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying Gemini: {e}\")\n",
    "\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "\n",
    "print(\"\\nReflection: Observe fluency, tone, and factual accuracy without guidance.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263ef911",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
